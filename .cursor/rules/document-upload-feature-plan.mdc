---
alwaysApply: true
---
Project Plan: Native Document and Image Upload with Gemini
This plan outlines the modern and correct way to implement a file upload feature. We will leverage Gemini's native multimodal capabilities to understand PDF and image files directly, eliminating the need for separate OCR or text extraction libraries.

Why this approach is better:

Simpler Code: We no longer need libraries like pdf-parse. The backend logic is reduced to a single API call to Gemini.

More Powerful: Gemini won't just read the text; it will understand the context from charts, images, and layout within the document.

Handles Both PDF & Images: The same API call can process both file types.

Phase 1: Frontend - The File Upload UI
Goal: Create the user interface for selecting and uploading a file.

(This phase remains the same as the previous plan, as the user-facing part is unchanged.)

Steps:

Add an Upload Button:

In your chat input area, add a "paperclip" icon button.

This button will trigger a hidden file input: <input type="file" id="file-upload" accept=".pdf, .png, .jpg, .jpeg" style="display: none;" />

Handle File Selection:

Use the onChange event on the file input to get the selected File object.

Upload the File to the Backend:

Create a FormData object and append the selected file to it.

Use fetch to POST this FormData to a new backend API endpoint: /api/analyze-document.

Provide UI Feedback:

Show a loading message like, "Gemini is reading document_name.pdf...".

When the process is complete, display a confirmation message in the chat.

Phase 2: Backend - The Document Analysis API
Goal: Create a new API route that receives a file and uses Gemini's native understanding to get information from it.

Steps:

Create the API Route File:

Create the file: /app/api/analyze-document/route.ts.

Handle the File Upload:

Install formidable: Use this library to parse the multipart/form-data request and easily access the uploaded file.

npm install formidable

Use formidable in your API route to get the file's temporary path and its mimetype (e.g., application/pdf, image/jpeg).

Prepare the File for Gemini:

Read the file from its temporary path into a buffer.

Convert the buffer to a Base64 encoded string. This is the format Gemini expects for inline data.

// Conceptual code inside your API route
import fs from 'fs';
const fileBuffer = fs.readFileSync(filePath);
const fileBase64 = fileBuffer.toString('base64');

Call the Gemini API (The Core Logic):

This is the new, simplified step. We will make a single call to a multimodal model like gemini-1.5-flash.

Construct the contents array with a text prompt and the file data.

// Conceptual code inside your API route
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

const contents = [
    { text: "Briefly summarize the key points of this document. This summary will be used as context for a chat." },
    {
        inlineData: {
            mimeType: theFileMimeType, // e.g., 'application/pdf'
            data: fileBase64
        }
    }
];

const result = await model.generateContent({ contents });
const summary = result.response.text();

Return the Summary:

Send the summary text back to the frontend in a JSON response.

{
  "summary": "The AI-generated summary of the document..."
}

Phase 3: Integrating the Context into the Chat
Goal: Use the AI-generated summary as context for the character AI.

(This phase is also unchanged in its goal, but it's now powered by a much better summary.)

Steps:

Receive and Store Context:

In the frontend, when the fetch call to /api/analyze-document succeeds, get the summary from the response.

Store this summary in a state variable (e.g., documentContext).

Inject Context into the Next Message:

When the user sends their next message, prepend the documentContext to the conversation history you send to your main chat API. This provides the character with the necessary information from the document.

Example Request Body:

{
  "chatHistory": [
    // ... previous messages ...
    { "role": "user", "parts": [{ "text": "[CONTEXT FROM UPLOADED DOCUMENT]:\n" + documentContext }] },
    // The user's new message
    { "role": "user", "parts": [{ "text": "Based on that, what do you think?" }] }
  ]
}

Clear the documentContext state after sending it so it's only used once.